{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35801b2788d5d15b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:31:03.979939Z",
     "start_time": "2024-10-16T03:31:03.820409Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b77095036e5ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:33:16.355055Z",
     "start_time": "2024-10-16T03:33:16.255995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED    \n",
      "codellama:latest           8fdf8f752f6e    3.8 GB    8 days ago     \n",
      "minicpm-v:latest           1862d7d5fee5    5.5 GB    8 days ago     \n",
      "qwen2.5-coder:1.5b         237d5d4dc596    986 MB    13 days ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    2 weeks ago    \n",
      "llama3.2:latest            a80c4f17acd5    2.0 GB    2 weeks ago    \n",
      "gemma2:latest              ff02c3702f32    5.4 GB    2 weeks ago    \n",
      "codellama:7b               8fdf8f752f6e    3.8 GB    2 weeks ago    \n",
      "llama3.1:latest            42182419e950    4.7 GB    2 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a306d01a3513c9",
   "metadata": {},
   "source": [
    "## Prompt llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:03:17.790616Z",
     "start_time": "2024-10-06T10:03:17.786103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_llama_3_prompt(user, system=\"\", assistant=\"\"):\n",
    "    system_prompt = \"\"\n",
    "    if system:\n",
    "        system_prompt = (\n",
    "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
    "        )\n",
    "\n",
    "    user_prompt = f\"<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|>\"\n",
    "    assistant_prompt = f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{assistant}<|eot_id|>\" if assistant else \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "    return f\"<|begin_of_text|>{system_prompt}{user_prompt}{assistant_prompt}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71514d941fd2bba9",
   "metadata": {},
   "source": [
    "## Define SQL schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af45ebadede899a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:03:20.092045Z",
     "start_time": "2024-10-06T10:03:20.088241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_movie_schema():\n",
    "    return \"\"\"\\\n",
    "    0|Title|TEXT eg. \"Inception\"\n",
    "    1|Director|TEXT eg. \"Christopher Nolan\"\n",
    "    2|Year|INT eg. \"2010\"\n",
    "    3|Rating|TEXT eg. \"PG-13\"\n",
    "    4|Runtime|TEXT eg. \"148 min\" castable to int\n",
    "    5|Genre|TEXT eg. \"Sci-Fi\"\n",
    "    6|Box_Office|TEXT eg. \"$829,895,144\" and when null has a value \"N/A\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434daef65cd5e5b1",
   "metadata": {},
   "source": [
    "## Build up prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e237201ea0d0abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:10:01.951993Z",
     "start_time": "2024-10-06T10:10:01.947278Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_question_and_query():\n",
    "    system = \"You are a data analyst with 10 years of experience writing complex SQL queries.\\n\"\n",
    "    system += (\n",
    "        \"Consider a table called 'movies' with the following schema (columns)\\n\"\n",
    "    )\n",
    "    system += get_movie_schema()\n",
    "    system += \"Consider the following questions, and queries used to answer them:\\n\"\n",
    "\n",
    "    question = \"\"\"What is the highest-grossing movie of all time?\"\"\"\n",
    "    sql = \"SELECT Title, Box_Office FROM movies WHERE Box_Office != 'N/A' ORDER BY CAST(REPLACE(Box_Office, ',', '') AS INTEGER) DESC LIMIT 1;\"\n",
    "\n",
    "    system += \"Question: \" + question + \"\\n\"\n",
    "    system += \"Query: \" + sql + \"\\n\"\n",
    "\n",
    "    user = \"Write a question and a query that are similar but different to those above.\\n\"\n",
    "    user += \"Format the question and query as a JSON object, i.e.\\n\"\n",
    "    user += '{\"question\" : str, \"sql_query\": str }.\\n'\n",
    "\n",
    "    user += \"Make sure to only return me valid sqlite SQL query generated as response to the question. Don't give me any comments. Just return question and query as JSON objects. Make sure query is relevant to the question. Make sure each query is complete and ends with a ;\\n\"\n",
    "\n",
    "    prompt = make_llama_3_prompt(user, system)\n",
    "\n",
    "    # Generate the result from the model\n",
    "    # result = ollama.generate(model='llama3.1', prompt=prompt)\n",
    "    # result = ollama.generate(model='llama3.2', prompt=prompt)\n",
    "    result = ollama.generate(model='gemma2', prompt=prompt)\n",
    "\n",
    "    # Inspect and parse the result['response']\n",
    "    response_str = result['response']\n",
    "    try:\n",
    "        response_dict = json.loads(response_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse response as JSON:\", e)\n",
    "        response_dict = {}\n",
    "\n",
    "    return response_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b381ecb77b4d9",
   "metadata": {},
   "source": [
    "## Write to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd9120159a8cfc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:03:28.370579Z",
     "start_time": "2024-10-06T10:03:28.366201Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_to_jsonl(data, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ca4eca0aec385",
   "metadata": {},
   "source": [
    "## Generate Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6331c835ee7054bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:11:38.756327Z",
     "start_time": "2024-10-06T10:10:05.215729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse response as JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Saved 10 questions and queries to questions_queries.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'questions_queries.jsonl'\n",
    "num_iterations = 10  # Define how many questions and queries you want to generate\n",
    "all_questions_queries = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    question_and_query = generate_question_and_query()\n",
    "    all_questions_queries.append(question_and_query)\n",
    "\n",
    "save_to_jsonl(all_questions_queries, output_file_path)\n",
    "print(f\"Saved {num_iterations} questions and queries to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
